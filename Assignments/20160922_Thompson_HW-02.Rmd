---
title: "20160922_Thompson_MLE_HW-02"
author: "Nick Thompson"
date: "9/16/2016"
output: html_document
header-includes:
  - \setlength{\parindent}{4em}
  - \setlength{\parskip}{0em}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
cat("\014")
library(dplyr)
library(ggplot2)
library(tidyr)
library(stargazer)
setwd("/Users/Nick/Documents/GitHubRepo/729_Reed_MLE_git/Assignments")
#wdata <- read.table("world.csv", sep = ",",header = T)
#save(wdata, file = "wdata.RData")
load("wdata.RData")
options(scipen = 999)
```

<center> <h1>Homework 2 - GVPT 729A</h1> </center>

Answer the following questions. Include your code, and report all the results you used to answer the questions.

https://raw.githubusercontent.com/Neilblund/729A/master/data/world.csv

The dataset at the link above contains information on cross national voter turnout (votevap) among the voting eligible population and per-capita GDP (gdppcap08).

1. Estimate the effect of per-capita GDP on voter turnout using OLS.

```{r ols, include=TRUE}
ols_01 <- lm(wdata$vote~wdata$gdppcap08); ols_01
stargazer(ols_01, type = "text")
```

2. Estimate the effect of per-capita GDP on voter turnout using the maximum likelihood estimator.

```{r MLE estimator, include=TRUE}
# log-likelihood for normal
ll.fn.norm <- function(mu, y) {
  -sum((y - mu)^2)
}


# function to estimate normal model
est.norm <- function(y) {
  est <- optim(par = 0, fn = ll.fn.norm, y = y,
               control = list(fnscale = -1),
               method = "Brent",  # for 1d problems
               lower = -100, upper = 100)
  if (est$convergence != 0) print("Model did not converge!")
  res <- list(est = est$par)
  return(res)
}

est.norm(wdata$votevap)

```

3. Take random samples of size 40, 30, and 20 from your dataset. Estimate the same model you used in questions to answer questions 1 and 2, and compare your results.

```{r Random Samples, include=FALSE}
# take a random sample of size 40,30, and 20 from a dataset wdata 
# sample without replacement
sample.40 <- wdata[sample(1:nrow(wdata), 40,
  	replace=FALSE),]
sample.30 <- wdata[sample(1:nrow(wdata), 30,
  	replace=FALSE),]
sample.20 <- wdata[sample(1:nrow(wdata), 20,
  	replace=FALSE),]
```
```{r Random Sample OLS, include=TRUE}
ols_40 <- lm(sample.40$vote~sample.40$gdppcap08)
ols_30 <- lm(sample.30$vote~sample.30$gdppcap08)
ols_20 <- lm(sample.20$vote~sample.20$gdppcap08)
stargazer(ols_40,ols_30,ols_20, type='text',
          column.labels = c("Random 40", "Random 30", 'Random 20'),
          column.separate = c(1, 1),
          model.numbers = FALSE,
          model.names = F)
```
    * What differences do you notice between the OLS and MLE results? 

    * What characteristics of MLE and OLS estimators explain these differences?

## notes

* Turning off scientific notation can make it a little easier to make comparisons between your results. Use the command:
```{r options,include=TRUE} 
options(scipen=999)
```
To turn off scientific notation. Turn it back on by resetting ”scipen=0”

* You can format your tables however you see fit, but make sure you include the relevant information.

* http://www.statmethods.net/management/subset.html has code for taking random subsets from a data frame.

* If you want to reproduce your results later, you can set R’s random number seed with this command:

*<span style="color:purple">#the number itself doesn't matter</span>*

```{r set seed, include=TRUE}
set.seed(1000)
```

