---
title: "Homework 4 - GVPT 729A"
author: "Nick Thompson"
date: "10/2/2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(foreign)
library(stargazer)
library(knitr)
library(gmodels)
library(dplyr)
library(ggplot2)
library("devtools")
library(obsval)
library(mvtnorm)
library(arm)
rm(list=ls())
cat("\014")
```

Answer the following questions. Include your code, and report all the re- sults you used to answer the questions. https://raw.githubusercontent.com/Neilblund/729A/master/data/voterid.csv

```{r data, include=TRUE}
setwd("~/Documents/GitHubRepo/729_Reed_MLE_git/Assignments")
#voterid <- read.csv(file = "https://raw.githubusercontent.com/Neilblund/729A/master/data/voterid.csv", header = TRUE, sep = ",")
#save(voterid2, file = "voterid2.RData")
load("voterid.RData")
#View(voterid2)
```

The link above contains data from ``Hicks et al. 2015:  A Principle or a Strategy?  Voter Identification Laws and Partisan Competition in the American States''

* `photo` is equal to $1$ if a state has legislation that requires voters to show photo ID at the polling booth, and $0$ if they do not have to have this requirement.

* `fraud` is the average number of voter fraud cases prosecuted in a given state since 2001.

* `election_margin` is the average partisan vote margin ($\%$ Republican - $\%$ Democratic) in a state since 2001.

* `gopleg` is the average $\%$ of a state's legislature that is Republican.

# Questions

1. Run a probit regression using photo as the dependent variable, and fraud, election margin and gopleg as independent variables. Obtain predicted probabilities that photo = 1 at two different values of one of your independent variables using the observed values approach.

```{r probit, include=TRUE}
#descriptive statistics for all variables
#stargazer(voterid, type = 'text')
# run probit, show results
voterid2 <- na.omit(voterid)
#View(voterid2)
voterid2$mean_gopleg <- mean(voterid2$gopleg)
voterid2$sd_gopleg <- 0.5*sd(voterid2$gopleg)
voterid2$med_g = median(voterid2$gopleg)
stargazer(voterid2, type = 'text')
g <- ggplot(voterid2,aes(x=gopleg))
g + geom_histogram(aes(y=..density..),binwidth = 7.5) +
  geom_density() +
  geom_vline(xintercept = voterid2$mean_gopleg,linetype='longdash') +
  geom_vline(xintercept = voterid2$med_g)
gopleg_obs_low <- voterid2$mean_gopleg - voterid2$sd_gopleg
gopleg_obs_high <- voterid2$mean_gopleg + voterid2$sd_gopleg


# run probit, show results
(model_1 <- glm('photo ~ fraud + election_margin + gopleg', 
               family = binomial(link = "probit"), 
               data = voterid2)) 

summary(model_1)
#stargazer(model_1,type = 'text')

# generate predicted probabilities automatically
voterid2$pprob <- predict(model_1,type="response")

# generate predicted probabilities manually
voterid2$pprob_manual <- pnorm(model_1$coef['(Intercept)'] +
                                 model_1$coef['fraud']*voterid2$fraud +
                                 model_1$coef['election_margin']*voterid2$election_margin +
                                 model_1$coef['gopleg']*voterid2$gopleg)

# test that we did it right
voterid2$pprob_test <- voterid2$pprob - voterid2$pprob_manual
summary(voterid2$pprob_test) # should be zeros

#######1. calculate average effect of photo using observed values----
voterid2$pprob_gopleg_upsd <- pnorm(model_1$coef['(Intercept)'] + 
                                 model_1$coef['fraud']*voterid2$fraud + 
                                 model_1$coef['election_margin']*voterid2$election_margin + 
                                 model_1$coef['gopleg']*gopleg_obs_high)
summary(voterid2$pprob_gopleg_upsd)

voterid2$pprob_gopleg_downsd <- pnorm(model_1$coef['(Intercept)'] + 
                                 model_1$coef['fraud']*voterid2$fraud + 
                                 model_1$coef['election_margin']*voterid2$election_margin + 
                                 model_1$coef['gopleg']*gopleg_obs_low)
summary(voterid2$pprob_gopleg_downsd)

voterid2$pprob_effect <- voterid2$pprob_gopleg_upsd - voterid2$pprob_gopleg_downsd
summary(voterid2$pprob_effect)		

```

**Based upon a histogram plot of the `gopleg`, I chose to use one standard deviation distance as my two points.  One half of a standard deviation below the mean and one half above for `gopleg`.  The probability that `photo` $=1$ when `gopleg` is $\frac{1}{2}$ standard deviation above its mean is `r mean(voterid2$pprob_gopleg_upsd)`, and the probability that `photo` $=1$ when `gopleg` is $\frac{1}{2}$ standard deviation below its mean is `r mean(voterid2$pprob_gopleg_downsd)`  The difference between the two is `r mean(voterid2$pprob_effect)`.**

2.  Use the “for loops” code to simulate ten draws from a set of random coefficients (see note 1). Calculate the mean difference between the two hypothetical scenarios, and report the 95% confidence interval around your results.

```{r loops - 01, include = TRUE, warning=FALSE}
##
##########2. Iterative for loops (ie, slow way)----
## 

n.draws <- 10
set.seed(42)
sim.coefs <- rmvnorm(n.draws, model_1$coef, vcov(model_1)) 
sim.coefs
p.effect.mean <- numeric(n.draws)
p.high.mean <- numeric(n.draws)
p.low.mean	<- numeric(n.draws)
p.baseline 	<- numeric(n.draws)

n.obs <- length(voterid2[[1]])

for(i in 1:n.draws){ 
  
  # For the current set of coefficients, calculate a
  # latent probability for all observations using observed values
  
  # first, set up vectors to store our linear predictors
  Xb.baseline 	<- numeric(n.obs)
  Xb.high 	<- numeric(n.obs)
  Xb.low	 	<- numeric(n.obs)
  
  # second, for current set of coefs, loop through each observation
  # and calculate mean, high and low linear predictors
  for(j in 1:n.obs){
    Xb.baseline[j] <- sim.coefs[i,1] +
      sim.coefs[i,2]*voterid2$fraud[j] + 
      sim.coefs[i,3]*voterid2$election_margin[j] + 
      sim.coefs[i,4]*voterid2$gopleg[j] 
    
    
    Xb.high[j] <- sim.coefs[i,1] + 
      sim.coefs[i,2]*voterid2$fraud[j] + 
      sim.coefs[i,3]*voterid2$election_margin[j] + 
      sim.coefs[i,4]*gopleg_obs_high
    
    Xb.low[j] <- sim.coefs[i,1] + 
      sim.coefs[i,2]*voterid2$fraud[j] + 
      sim.coefs[i,3]*voterid2$election_margin[j] + 
      sim.coefs[i,4]*gopleg_obs_low   
  }
  
  # third, transform linear predictors into probabilites
  predict.baseline	<- pnorm(Xb.baseline)
  predict.high	<- pnorm(Xb.high)
  predict.low 	<- pnorm(Xb.low)
  predict.effect  <- predict.high - predict.low
  
  # fourth, for current set of coefs, store the average mean, high and 
  # low probability across all observations in the data set 
  p.baseline[i]		<-mean(predict.baseline, na.rm=TRUE)
  p.high.mean[i]	<- mean(predict.high, na.rm=TRUE)
  p.low.mean[i]	<- mean(predict.low, na.rm=TRUE)
  p.effect.mean[i] <- mean(predict.effect,na.rm=TRUE) 
  
}

summary(p.effect.mean)
quantile(p.effect.mean, c(.025,.975))

```

3.  Use the “obsval” command to create 1000 simulated coefficients. Report the average effect and the 95% confidence interval around your results. (see note 2)

```{r obsval command, include=TRUE, warning=FALSE}
#4. FUNCTIONAL WAY----

mod2 <- obsval(photo~fraud+election_margin+gopleg,
              data = voterid2, 
              reg.model = "probit",
              n.draws = 1000,
              effect.var = "gopleg", 
              effect.vals = c(gopleg_obs_low,gopleg_obs_high), # 1/2 SD below & 1/2 SD above mean
              verbose = TRUE)

# display model results
summary(mod2$model)

# get mean effect of 'gopleg'
mean(mod2$effect.preds) 
mod2$effect.mean
mean(mod2$preds[, 2] - mod2$preds[, 1])
names(mod2)

head(mod2$sim.coefs)

mod2$effect.high.ci
mod2$effect.low.ci
quantile(mod2$effect.preds, c(0.025, 0.975))

# Histograms of the two predicted distributions
hist(p.effect.mean, main = "Question 2")
hist(mod2$effect.preds, main = "Question3")

```

There is a decided difference between the outcomes from question two and question three.  In question two we see confidence intervals from [`r quantile(p.effect.mean, c(0.025,0.975))`].  In question three we see a confidence interval from [`r mod2$effect.high.ci`, `r mod2$effect.low.ci`].  As seen in the two histograms above, the `1,000` draw model has a normal shape while the `10` draw model is not normal.  Based upon these outcomes, we can assume the confidence interval from question three is more accurate.

# notes

1.  The obsval-demo.R script contains a worked example of doing this using the Hanmer and Kalkan data. The code section labeled “2. Iterative for loops (ie, slow way)” has instructions. Keep in mind that you will need to install and load the mvtnorm package to make this work.

2.  This will require you to install the obsval package and its dependencies. An example of using the obsval function is in the code section labeled “4. FUNCTIONAL WAY” in the obsval-demo.R script.

3.  If you’re not familiar with loops in R you might be struggling to read some of the code provided. Take a look at this R-bloggers post for a simple explanation of how loops work.

